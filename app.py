# app.py
"""
AI ç§‘ç ”æ–‡çŒ®åŠ©æ‰‹ - Streamlit ç•Œé¢
"""
import streamlit as st
import os
from src.knowledge_base import knowledge_base as kb
from src.chains import assistant

# ===== é¡µé¢é…ç½® =====
st.set_page_config(
    page_title="ğŸ“š AI ç§‘ç ”åŠ©æ‰‹",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== ä¾§è¾¹æ  =====
with st.sidebar:
    st.title("ğŸ“š AI ç§‘ç ”åŠ©æ‰‹")
    st.caption("ä½ çš„æ–‡çŒ®ç¬¬äºŒå¤§è„‘")

    st.divider()

    # çŸ¥è¯†åº“ç»Ÿè®¡
    stats = kb.get_stats()
    st.metric("ğŸ“„ è®ºæ–‡æ€»æ•°", stats["total_papers"])
    st.metric("ğŸ“¦ çŸ¥è¯†å—æ•°", stats["total_chunks"])

    if stats["top_keywords"]:
        st.subheader("ğŸ·ï¸ çƒ­é—¨å…³é”®è¯")
        for kw, count in stats["top_keywords"][:5]:
            st.write(f"- {kw} ({count})")

    st.divider()

    # ä¸Šä¼ è®ºæ–‡
    st.subheader("ğŸ“¤ ä¸Šä¼ è®ºæ–‡")
    uploaded_file = st.file_uploader(
        "é€‰æ‹© PDF æ–‡ä»¶",
        type=["pdf"],
        help="æ”¯æŒä¸Šä¼ å­¦æœ¯è®ºæ–‡ PDF"
    )

    if uploaded_file:
        # ä¿å­˜æ–‡ä»¶
        save_path = os.path.join("data/papers", uploaded_file.name)
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        with st.spinner("æ­£åœ¨è§£æè®ºæ–‡..."):
            try:
                metadata = kb.add_paper(save_path)
                st.success(f"âœ… å·²æ·»åŠ : {metadata.title}")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ æ·»åŠ å¤±è´¥: {e}")

# ===== ä¸»ç•Œé¢ =====
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ’¬ æ™ºèƒ½é—®ç­”",
    "ğŸ“ è®ºæ–‡æ€»ç»“",
    "ğŸ” å¯¹æ¯”åˆ†æ",
    "âœï¸ å†™ä½œåŠ©æ‰‹",
    "ğŸ“š è®ºæ–‡åˆ—è¡¨"
])

# ----- Tab 1: æ™ºèƒ½é—®ç­” -----
with tab1:
    st.header("ğŸ’¬ é—®é—®ä½ çš„æ–‡çŒ®åº“")
    st.caption("é—®ä»»ä½•å…³äºä½ è¯»è¿‡çš„è®ºæ–‡çš„é—®é¢˜")

    # ç¤ºä¾‹é—®é¢˜
    example_questions = [
        "æˆ‘è¯»è¿‡å“ªäº›å…³äº Transformer çš„è®ºæ–‡ï¼Ÿ",
        "XXX æ–¹æ³•çš„ä¼˜ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æœ‰å“ªäº›è®ºæ–‡ä½¿ç”¨äº† YYY æ•°æ®é›†ï¼Ÿ",
        "å¯¹æ¯”ä¸€ä¸‹ A æ–¹æ³•å’Œ B æ–¹æ³•",
    ]

    st.write("ğŸ’¡ **ç¤ºä¾‹é—®é¢˜ï¼š**")
    cols = st.columns(2)
    for i, q in enumerate(example_questions):
        if cols[i % 2].button(q, key=f"example_{i}"):
            st.session_state.qa_input = q

    # è¾“å…¥æ¡†
    question = st.text_input(
        "è¾“å…¥ä½ çš„é—®é¢˜ï¼š",
        value=st.session_state.get("qa_input", ""),
        placeholder="ä¾‹å¦‚ï¼šXXX æ–¹æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
    )

    if st.button("ğŸ” æœç´¢", type="primary") and question:
        with st.spinner("æ­£åœ¨æ£€ç´¢å’Œæ€è€ƒ..."):
            answer = assistant.ask(question)

        st.markdown("### ğŸ“– å›ç­”")
        st.markdown(answer)

        # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£
        with st.expander("ğŸ“„ æŸ¥çœ‹ç›¸å…³åŸæ–‡"):
            docs = kb.search(question, k=3)
            for doc in docs:
                st.info(f"**æ¥æº:** {doc.metadata.get('title', 'Unknown')}")
                st.write(doc.page_content[:500] + "...")
                st.divider()

# ----- Tab 2: è®ºæ–‡æ€»ç»“ -----
with tab2:
    st.header("ğŸ“ è®ºæ–‡æ€»ç»“")
    st.caption("å¿«é€Ÿå›é¡¾ä¸€ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹")

    papers = kb.list_papers()

    if papers:
        paper_titles = [p.title for p in papers]
        selected_paper = st.selectbox("é€‰æ‹©è®ºæ–‡ï¼š", paper_titles)

        if st.button("ğŸ“‹ ç”Ÿæˆæ€»ç»“", type="primary"):
            with st.spinner("æ­£åœ¨æ€»ç»“..."):
                summary = assistant.summarize_paper(selected_paper)
            st.markdown(summary)
    else:
        st.info("ğŸ“­ çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ è®ºæ–‡")

# ----- Tab 3: å¯¹æ¯”åˆ†æ -----
with tab3:
    st.header("ğŸ” æ–¹æ³•å¯¹æ¯”")
    st.caption("å¯¹æ¯”åˆ†æä¸åŒæ–¹æ³•æˆ–è®ºæ–‡")

    compare_topic = st.text_input(
        "è¾“å…¥è¦å¯¹æ¯”çš„ä¸»é¢˜ï¼š",
        placeholder="ä¾‹å¦‚ï¼šBERT vs GPT, æˆ–è€…ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„ä¸åŒå®ç°"
    )

    if st.button("âš–ï¸ å¼€å§‹å¯¹æ¯”", type="primary") and compare_topic:
        with st.spinner("æ­£åœ¨åˆ†æ... "):
            comparison = assistant.compare(compare_topic)
        st.markdown(comparison)

# ----- Tab 4: å†™ä½œåŠ©æ‰‹ -----
with tab4:
    st.header("âœï¸ å†™ä½œåŠ©æ‰‹")

    writing_mode = st.radio(
        "é€‰æ‹©åŠŸèƒ½ï¼š",
        ["ğŸ“š ç”Ÿæˆ Related Work", "ğŸ’¡ ç ”ç©¶æƒ³æ³•å¤´è„‘é£æš´"]
    )

    if writing_mode == "ğŸ“š ç”Ÿæˆ Related Work":
        topic = st.text_area(
            "è¾“å…¥ç ”ç©¶ä¸»é¢˜ï¼š",
            placeholder="æè¿°ä½ çš„ç ”ç©¶ä¸»é¢˜ï¼Œç³»ç»Ÿä¼šåŸºäºçŸ¥è¯†åº“ç”Ÿæˆ Related Work æ®µè½"
        )

        if st.button("ğŸ“ ç”Ÿæˆ", type="primary") and topic:
            with st.spinner("æ­£åœ¨ç”Ÿæˆ..."):
                related_work = assistant.generate_related_work(topic)
            st.markdown("### ç”Ÿæˆçš„ Related Work")
            st.markdown(related_work)

            # å¤åˆ¶æŒ‰é’®
            st.code(related_work, language="markdown")

    else:  # å¤´è„‘é£æš´
        idea = st.text_area(
            "è¾“å…¥ä½ çš„ç ”ç©¶æƒ³æ³•ï¼š",
            placeholder="æè¿°ä½ çš„ç ”ç©¶æƒ³æ³•ï¼ŒAI ä¼šå¸®ä½ æ‹“å±•æ€è·¯"
        )

        if st.button("ğŸ§  å¤´è„‘é£æš´", type="primary") and idea:
            with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                brainstorm = assistant.brainstorm(idea)
            st.markdown(brainstorm)

# ----- Tab 5: è®ºæ–‡åˆ—è¡¨ -----
with tab5:
    st.header("ğŸ“š æˆ‘çš„è®ºæ–‡åº“")

    papers = kb.list_papers()

    if papers:
        # æœç´¢è¿‡æ»¤
        search_term = st.text_input("ğŸ” æœç´¢è®ºæ–‡ï¼š", placeholder="è¾“å…¥æ ‡é¢˜æˆ–å…³é”®è¯")

        filtered_papers = papers
        if search_term:
            filtered_papers = [
                p for p in papers
                if search_term.lower() in p.title.lower()
                   or search_term.lower() in " ".join(p.keywords).lower()
            ]

        st.write(f"å…± {len(filtered_papers)} ç¯‡è®ºæ–‡")

        for paper in filtered_papers:
            with st.expander(f"ğŸ“„ {paper.title}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ä½œè€…:** {', '.join(paper.authors)}")
                    st.write(f"**å¹´ä»½:** {paper.year or 'æœªçŸ¥'}")
                    st.write(f"**ä¼šè®®/æœŸåˆŠ:** {paper.venue or 'æœªçŸ¥'}")
                with col2:
                    st.write(f"**å…³é”®è¯:** {', '.join(paper.keywords)}")
                    st.write(f"**æ·»åŠ æ—¶é—´:** {paper.added_date}")

                if paper.abstract:
                    st.write("**æ‘˜è¦:**")
                    st.write(paper.abstract)
    else:
        st.info("ğŸ“­ è¿˜æ²¡æœ‰æ·»åŠ ä»»ä½•è®ºæ–‡ï¼Œè¯·é€šè¿‡ä¾§è¾¹æ ä¸Šä¼ ")

# ===== é¡µè„š =====
st.divider()
st.caption("ğŸ§  AI ç§‘ç ”åŠ©æ‰‹ | åŸºäº LangChain + Ollama æ„å»º")